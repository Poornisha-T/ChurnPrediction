# -*- coding: utf-8 -*-
"""Survey_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ceSN34jeNItKipSTuvONVJI4rMbLEyRj
"""

from google.colab import drive
drive.mount('/content/drive')

data = '/content/drive/MyDrive/Bank_churn.csv'

import pandas as pd
df = pd.read_csv(data)

"""**EDA**"""

df.head()

df.describe()

df.shape

df.duplicated().sum()

from sklearn.preprocessing import LabelEncoder
label_encoders = {}
for column in ['geography', 'gender']:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

df.info()

df = df.drop(columns=['surname'])

df = df.drop(columns=['customerid'])

df = df.drop(columns=['rownumber'])

import matplotlib.pyplot as plt
import seaborn as sns

datacorr = df.corr()
plt.figure(figsize=(15, 15))
sns.heatmap(datacorr, annot = True, square = True)

"""**Feature Engineering**"""

import warnings
warnings.filterwarnings('ignore')

plt.figure(figsize=(15, 15))

for i, column in enumerate(df.columns):
    plt.subplot(5, 3, i+1)
    sns.distplot(df[column])
    plt.title(column)

plt.tight_layout()
plt.show()

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df[['creditscore', 'age', 'balance']])

churn_counts = df['churn'].value_counts()
print(churn_counts)

import pandas as pd
from imblearn.over_sampling import SMOTE
sm = SMOTE(sampling_strategy='minority', random_state=42)
oversampled_X, oversampled_Y = sm.fit_resample(df.drop('churn', axis=1), df['churn'])
oversampled = pd.concat([pd.DataFrame(oversampled_X), pd.DataFrame(oversampled_Y)], axis=1)

oversampled

churn_counts = oversampled['churn'].value_counts()
print(churn_counts)

x = oversampled.iloc[:,:-1]
y = oversampled.iloc[:,-1]

scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, random_state = 42, test_size = 0.2)

"""Logistic Regression

"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import r2_score,accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, f1_score
lr_model = LogisticRegression()
lr_model.fit(x_train, y_train)

lr_y_pred = lr_model.predict(x_test)

lr_accuracy = accuracy_score(y_test, lr_y_pred)
lr_precision = precision_score(y_test, lr_y_pred)
lr_recall = recall_score(y_test, lr_y_pred)
lr_f1 = f1_score(y_test, lr_y_pred)

print("Accuracy:", lr_accuracy)
print("Precision:", lr_precision)
print("Recall:", lr_recall)
print("F1 Score:", lr_f1)

pip install lime

"""LIME - Local explanation of how does the LR model classifies the first test data

"""

import lime
import lime.lime_tabular
explainer = lime.lime_tabular.LimeTabularExplainer(x_train, mode='classification', feature_names=x.columns)

instance = x_test[0]
exp = explainer.explain_instance(instance, lr_model.predict_proba)

exp.show_in_notebook(show_table=True)

cm = confusion_matrix(y_test, lr_y_pred)

sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier()
rf_model.fit(x_train, y_train)

rf_y_pred = rf_model.predict(x_test)

rf_accuracy = accuracy_score(y_test, rf_y_pred)
rf_precision = precision_score(y_test, rf_y_pred)
rf_recall = recall_score(y_test, rf_y_pred)
rf_f1 = f1_score(y_test, rf_y_pred)

print("Accuracy:", rf_accuracy)
print("Precision:", rf_precision)
print("Recall:", rf_recall)
print("F1 Score:", rf_f1)

explainer = lime.lime_tabular.LimeTabularExplainer(x_train, mode='classification', feature_names=x.columns)

instance = x_test[0]
exp = explainer.explain_instance(instance, rf_model.predict_proba)

exp.show_in_notebook(show_table=True)

cm = confusion_matrix(y_test, rf_y_pred)

sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""XGBOOST classfier

"""

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

xgb_model = XGBClassifier()

xgb_model.fit(x_train, y_train)
xgb_y_pred = xgb_model.predict(x_test)

xgb_accuracy = accuracy_score(y_test, xgb_y_pred)
xgb_precision = precision_score(y_test, xgb_y_pred)
xgb_recall = recall_score(y_test, xgb_y_pred)
xgb_f1 = f1_score(y_test, xgb_y_pred)

print("Accuracy:", xgb_accuracy)
print("Precision:", xgb_precision)
print("Recall:", xgb_recall)
print("F1 Score:", xgb_f1)

explainer = lime.lime_tabular.LimeTabularExplainer(x_train, mode='classification', feature_names=x.columns)

instance = x_test[0]
exp = explainer.explain_instance(instance, xgb_model.predict_proba)

exp.show_in_notebook(show_table=True)

cm = confusion_matrix(y_test, xgb_y_pred)

sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""SVM model"""

from sklearn.svm import SVC
svm_model = SVC(kernel='linear')

svm_model.fit(x_train, y_train)
svm_y_pred = svm_model.predict(x_test)

svm_accuracy = accuracy_score(y_test, svm_y_pred)
svm_precision = precision_score(y_test, svm_y_pred)
svm_recall = recall_score(y_test, svm_y_pred)
svm_f1 = f1_score(y_test, svm_y_pred)

print("Accuracy:", svm_accuracy)
print("Precision:", svm_precision)
print("Recall:", svm_recall)
print("F1 Score:", svm_f1)

cm = confusion_matrix(y_test, svm_y_pred)

sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Stacking Classifier"""

from sklearn.ensemble import StackingClassifier
estimators = [('lr', lr_model), ('rf', rf_model), ('svm', svm_model)]
stack = StackingClassifier(estimators=estimators)
stack.fit(x_train, y_train)
stack_y_pred_bal = stack.predict(x_test)

bal_stack_accuracy = accuracy_score(y_test, stack_y_pred_bal)
bal_stack_precision = precision_score(y_test, stack_y_pred_bal)
bal_stack_recall = recall_score(y_test, stack_y_pred_bal)
bal_stack_f1 = f1_score(y_test, stack_y_pred_bal)

print("Accuracy:", bal_stack_accuracy)
print("Precision:", bal_stack_precision)
print("Recall:", bal_stack_recall)
print("F1 Score:", bal_stack_f1)

cm = confusion_matrix(y_test, stack_y_pred_bal)

sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

import matplotlib.pyplot as plt

models = ['Linear Regression', 'Random Forest', 'XGBOOST', 'Support Vector Machine', 'Stacking']

accuracy_scores = [lr_accuracy, rf_accuracy, xgb_accuracy, svm_accuracy, bal_stack_accuracy]

plt.bar(models, accuracy_scores, color=['blue', 'green', 'orange', 'red'])

plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Comparison of Model Accuracies')
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt

models = ['Linear Regression', 'Random Forest', 'XGBOOST', 'Support Vector Machine', 'Stacking']

accuracy_scores = [lr_precision, rf_precision, xgb_precision, svm_precision, bal_stack_precision]

plt.bar(models, accuracy_scores, color=['blue', 'green', 'orange', 'red'])

plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Comparison of Model precision')
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt

models = ['Linear Regression', 'Random Forest', 'XGBOOST','Support Vector Machine', 'Stacking']

accuracy_scores = [lr_recall, rf_recall,xgb_recall, svm_recall, bal_stack_recall]

plt.bar(models, accuracy_scores, color=['blue', 'green', 'orange', 'red'])

plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Comparison of Model recall')
plt.xticks(rotation=45)
plt.show()

import pickle
filename = '/content/drive/MyDrive/stacking_model.pkl'
pickle.dump(stack, open(filename, 'wb'))

